{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "Copia de Analisis Geografico.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iviterirambay/DataAnalytics-MachineLearning/blob/main/Analisis_Geografico.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ms-tOC-sfD_6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4352f9ef-c3d9-4235-b7b0-9d91cc2dd24a"
      },
      "source": [
        "!pip install numpy scipy scikit-learn==0.19.2 spanish_sentiment_analysis ipython\n",
        "import os\n",
        "import json\n",
        "import re\n",
        "import sys\n",
        "import unicodedata\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from classifier import *"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (1.4.1)\n",
            "Requirement already satisfied: scikit-learn==0.19.2 in /usr/local/lib/python3.6/dist-packages (0.19.2)\n",
            "Requirement already satisfied: spanish_sentiment_analysis in /usr/local/lib/python3.6/dist-packages (1.0.0)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (5.5.0)\n",
            "Requirement already satisfied: marisa-trie in /usr/local/lib/python3.6/dist-packages (from spanish_sentiment_analysis) (0.7.5)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from spanish_sentiment_analysis) (3.2.5)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from spanish_sentiment_analysis) (0.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython) (0.7.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython) (2.6.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython) (50.3.2)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython) (0.8.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython) (4.4.2)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython) (4.3.3)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython) (1.0.18)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->spanish_sentiment_analysis) (1.15.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython) (0.6.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython) (0.2.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython) (0.2.5)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZiLiHQsfD_7"
      },
      "source": [
        "class FileStorage():\n",
        "\n",
        "    def __init__(self,filename):\n",
        "        self.filename = filename\n",
        "\n",
        "    def read(self):\n",
        "        if os.path.exists(self.filename):\n",
        "            with open(self.filename) as file:\n",
        "                data = json.load(file)\n",
        "                return data\n",
        "        else:\n",
        "            return {}\n",
        "        \n",
        "    def save(self,data):#write data like json file\n",
        "        try:\n",
        "            old_data = self.read()\n",
        "            if len(old_data.keys()) == 0:\n",
        "                old_data[\"tweets\"] = []\n",
        "            old_data[\"tweets\"].append(data)\n",
        "            jsondata = json.dumps(old_data, indent=4, skipkeys=True, sort_keys=True)\n",
        "            fd = open(self.filename, 'w')\n",
        "            fd.write(jsondata)\n",
        "            fd.close()\n",
        "            print (self.filename + \" ha sido escrito exitosamente\")\n",
        "        except Exception as e:\n",
        "            print (e)\n",
        "            print ('ERROR writing', self.filename)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4pRWQwWfD_7"
      },
      "source": [
        "def process(tweet):\n",
        "    tweet = tweet.lower()\n",
        "    tweet = re.sub(r\"(https?)\\S+\",\"\",tweet)#remove urls\n",
        "    tweet = re.sub(r\"(\\B#)\\w*\",\"\",tweet)#remove hashtags\n",
        "    tweet = re.sub(r\"(\\B@)\\w*\",\"\",tweet)#remove mentions\n",
        "    tweet = re.sub(\"\\n\",\"\",tweet)#remove lines separate\n",
        "    tweet = unicodedata.normalize('NFKD', tweet).encode('ASCII', 'ignore')#remove accents\n",
        "    tweet = re.sub('[^a-zA-Z ]+', ' ', tweet.decode('ASCII'))#remove punctuactions\n",
        "    text_no_stop_words = filter_stop_words(tweet)\n",
        "    tokens = [token for token in text_no_stop_words if len(token) > 2 ]\n",
        "    tweet = \" \".join(tokens)\n",
        "    return tweet\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def filter_stop_words(text):\n",
        "    stop_words_list = stopwords.words('spanish')\n",
        "    stop_words_list += stopwords.words('english')\n",
        "    text_filtered = [word for word in text.split() if word.lower() not in stop_words_list]\n",
        "    return text_filtered"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0dphK5sfD_7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0d86c04-6f4a-4083-e77a-78b4800b35ac"
      },
      "source": [
        "file_worker = FileStorage(\"buenos_aires.json\")\n",
        "data = file_worker.read()\n",
        "print(data['tweets'][10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'contributors': None, 'coordinates': None, 'created_at': 'Sat Nov 28 14:52:09 +0000 2020', 'entities': {'hashtags': [], 'symbols': [], 'urls': [], 'user_mentions': []}, 'favorite_count': 0, 'favorited': False, 'filter_level': 'low', 'geo': None, 'id': 1332698803904913410, 'id_str': '1332698803904913410', 'in_reply_to_screen_name': None, 'in_reply_to_status_id': None, 'in_reply_to_status_id_str': None, 'in_reply_to_user_id': None, 'in_reply_to_user_id_str': None, 'is_quote_status': False, 'lang': 'es', 'place': {'attributes': {}, 'bounding_box': {'coordinates': [[[-58.531792, -34.674453], [-58.531792, -34.534177], [-58.353494, -34.534177], [-58.353494, -34.674453]]], 'type': 'Polygon'}, 'country': 'Argentina', 'country_code': 'AR', 'full_name': 'Ciudad Autónoma de Buenos Aires, Argentina', 'id': '018f1cde6bad9747', 'name': 'Ciudad Autónoma de Buenos Aires', 'place_type': 'city', 'url': 'https://api.twitter.com/1.1/geo/id/018f1cde6bad9747.json'}, 'quote_count': 0, 'reply_count': 0, 'retweet_count': 0, 'retweeted': False, 'source': '<a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>', 'text': 'Hay alguien nas pelotudo que brancateli', 'timestamp_ms': '1606575129854', 'truncated': False, 'user': {'contributors_enabled': False, 'created_at': 'Mon Dec 31 12:37:59 +0000 2018', 'default_profile': True, 'default_profile_image': False, 'description': 'hincha del fortin , el ajrdrez ,la amistad y los buenos recuerdos', 'favourites_count': 40517, 'follow_request_sent': None, 'followers_count': 1585, 'following': None, 'friends_count': 3115, 'geo_enabled': True, 'id': 1079718308184756224, 'id_str': '1079718308184756224', 'is_translator': False, 'lang': None, 'listed_count': 0, 'location': 'Buenos Aires, Argentina', 'name': 'jorge paternoster', 'notifications': None, 'profile_background_color': 'F5F8FA', 'profile_background_image_url': '', 'profile_background_image_url_https': '', 'profile_background_tile': False, 'profile_banner_url': 'https://pbs.twimg.com/profile_banners/1079718308184756224/1584291008', 'profile_image_url': 'http://pbs.twimg.com/profile_images/1239232420551032834/MOqlOedz_normal.jpg', 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1239232420551032834/MOqlOedz_normal.jpg', 'profile_link_color': '1DA1F2', 'profile_sidebar_border_color': 'C0DEED', 'profile_sidebar_fill_color': 'DDEEF6', 'profile_text_color': '333333', 'profile_use_background_image': True, 'protected': False, 'screen_name': 'jorgepaternost3', 'statuses_count': 15892, 'time_zone': None, 'translator_type': 'none', 'url': None, 'utc_offset': None, 'verified': False}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igTy8Ui3fD_7"
      },
      "source": [
        "c = 0\n",
        "clf = SentimentClassifier()\n",
        "\n",
        "latitudes = []\n",
        "longitudes = []\n",
        "ids = []\n",
        "created_at = []\n",
        "users = []\n",
        "rts = []\n",
        "favs = []\n",
        "texts = []\n",
        "sent_scores = []\n",
        "followers = []\n",
        "links = []\n",
        "for tweet in data['tweets']:\n",
        "    if type(tweet['coordinates']) == dict:\n",
        "        lat = tweet['coordinates']['coordinates'][1]\n",
        "        lon = tweet['coordinates']['coordinates'][0]\n",
        "        fecha_hora = tweet['created_at']\n",
        "        id_ = tweet['id_str']\n",
        "        text = tweet['text']\n",
        "        text = process(text)\n",
        "        favorite_count = tweet['favorite_count']\n",
        "        retweet_count = tweet['retweet_count']\n",
        "        followers_count = tweet['user']['followers_count']\n",
        "        screen_name = tweet['user']['screen_name']\n",
        "        link = 'https://twitter.com/' + screen_name + '/status/' + id_\n",
        "        score = clf.predict(text)\n",
        "        \n",
        "        latitudes.append(lat)\n",
        "        longitudes.append(lon)\n",
        "        ids.append(id_)\n",
        "        created_at.append(fecha_hora)\n",
        "        texts.append(text)\n",
        "        favs.append(favorite_count)\n",
        "        rts.append(retweet_count)\n",
        "        followers.append(followers_count)\n",
        "        users.append(screen_name)\n",
        "        links.append(link)\n",
        "        sent_scores.append(score)\n",
        "        c+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqQV58ARfD_7"
      },
      "source": [
        "f = open('tweets_coordinates.csv', 'w')\n",
        "f.write('id,created_at,latitude,longitude,user_screen_name,retweets_count,favorites_count,text,followers_count,link,sentiment_score\\n')\n",
        "for i in range(c):\n",
        "    f.write(str(ids[i]) + ',' + created_at[i] + ',' + str(latitudes[i]) + ',' + str(longitudes[i]) + ',' + users[i] + ',' + str(rts[i]) + ',' + str(favs[i]) + ',' + texts[i] + ',' + str(followers[i]) + ',' + links[i] + ',' + str(sent_scores[i]) +'\\n')                   \n",
        "f.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xolLDQQLfD_7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "df2b2cd1-5a7b-4feb-a684-9e9b2693962c"
      },
      "source": [
        "#users[i] + ',' + rts[i] + ',' + favs[i] + ',' + texts[i] + ',' + followers[i] + ',' + links[i] + ',' + str(sent_scores[i]) +'\\n'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-ecd03971d4cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0musers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m','\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m','\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfavs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m','\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m','\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfollowers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m','\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlinks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m','\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: must be str, not int"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDEQo7NufD_7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpRUKsrtfD_7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}